#! usr/bin/env nextflow


if (params.singleEnds){
    datasets = Channel.fromPath(["$params.data_dir/*.fastq.gz", "$params.data_dir/*.fastq"])
                .map { file -> tuple(file.baseName, file) }
}
else {
    datasets = Channel.fromFilePairs(["$params.data_dir/*_R{1,2}*.fastq.gz", "$params.data_dir/*_R{1,2}*.fastq"])
}
design_ch = Channel.fromPath("$params.design")

println "$params.outdir"
// check https://rnabio.org/module-09-appendix/0009/12/01/StrandSettings/ for settings to use


/*
build index file out of reference genome
*/
process build_index {
    tag "$genome.baseName"
    cpus 4

    input:
    path genome from params.genome

    output:
    tuple val("$genome.baseName"), path("${genome.baseName}*") into index_ch

    script:
    """
    hisat2-build -p ${task.cpus} $genome $genome.baseName
    """
}


/*
run fastp with specified values
add adapter_trimming option, merging_option
read through all options of fastp
*/
process qc_trim {
    tag "$sample_id"
    cpus 4 

    input:
    tuple val(sample_id), path(reads) from datasets

    output:
    tuple val("$sample_id"), path('cleaned_R*.fastq.gz') into qc_out

    script:
    if (params.singleEnds)
        """
        fastp -i ${reads} -o cleaned_R1_${sample_id}.fastq.gz -h ${sample_id}.html -w ${task.cpus}
        """
    else
        """
        fastp -i ${reads[0]} -I ${reads[1]} -o cleaned_R1_${sample_id}.fastq.gz -O cleaned_R2_${sample_id}.fastq.gz -h ${sample_id}.html -w ${task.cpus}
        """
}

/*
align cleaned reads to reference genome
*/

process alignment {
    tag "$sample_id"
    publishDir "$params.outdir/hisat2_sum", pattern: "*.sum", mode: "copy"
    cpus 4

    input:
    tuple val(sample_id), path(clean_reads) from qc_out
    tuple val(genome_base), path(genome_idx) from index_ch

    output:
    tuple val("$sample_id"), path("*.bam") into align_ch, bam_ch
    path "*.sum"

    // option --rf for dUTP generated libraries
    // option --fr for libraries generated by Illumina SOLiD
    script:
    if (params.singleEnds) 
        if (params.strand == "r")
            """
            hisat2 --dta \
            --rna-strandness R \
            -x $genome_base \
            -p ${task.cpus} \
            -U ${clean_reads} \
            -S ${sample_id}.sam \
            --summary-file ${sample_id}.sum
            samtools sort -l 9 -O bam *.sam -o ${sample_id}.bam -@ ${task.cpus}
            """
        else if (params.strand == "f")
            """
            hisat2 --dta \
            --rna-strandness F \
            -x $genome_base \
            -p ${task.cpus} \
            -U ${clean_reads} \
            -S ${sample_id}.sam \
            --summary-file ${sample_id}.sum
            samtools sort -l 9 -O bam *.sam -o ${sample_id}.bam -@ ${task.cpus}
            """
        else if (params.strand == "u")
            """
            hisat2 --dta \
            -x $genome_base \
            -p ${task.cpus} \
            -U ${clean_reads} \
            -S ${sample_id}.sam \
            --summary-file ${sample_id}.sum
            samtools sort -l 9 -O bam *.sam -o ${sample_id}.bam -@ ${task.cpus}
            """
        else
            error "Invalid argument strand: ${strand}"
    else
        if (params.strand == "rf")
            """
            hisat2 --rf --dta \
            -x $genome_base \
            -p ${task.cpus} \
            -1 ${clean_reads[0]} \
            -2 ${clean_reads[1]} \
            -S ${sample_id}.sam \
            --summary-file ${sample_id}.sum
            samtools sort -l 9 -O bam *.sam -o ${sample_id}.bam -@ ${task.cpus}
            """
        else if (params.strand == "fr")
            """
            hisat2 --fr --dta \
            -x $genome_base \
            -p ${task.cpus} \
            -1 ${clean_reads[0]} \
            -2 ${clean_reads[1]} \
            -S ${sample_id}.sam \
            --summary-file ${sample_id}.sum
            samtools sort -l 9 -O bam *.sam -o ${sample_id}.bam -@ ${task.cpus}
            """
        else if (params.strand == "un")
            """
            hisat2 --dta \
            -x $genome_base \
            -p ${task.cpus} \
            -1 ${clean_reads[0]} \
            -2 ${clean_reads[1]} \
            -S ${sample_id}.sam \
            --summary-file ${sample_id}.sum
            samtools sort -l 9 -O bam *.sam -o ${sample_id}.bam -@ ${task.cpus}
            """
        else
            error "Invalid argument strand: ${strand}"
}

process assembly {
    tag "$sample_id"
    cpus 4

    input:
    tuple val(sample_id), path(bam) from align_ch
    path annot from params.annot

    output:
    path("*.gtf") into assembly_ch
    // --rf only needed for hisat, as necessary tags are already added in bam file
    script:
    """
    stringtie $bam \
    -o ${sample_id}.gtf \
    -G $annot \
    -p ${task.cpus} \
    """
}

process merge_gff {
    publishDir "$params.outdir", mode: "copy"

    input:
    path(gff) from assembly_ch.collect()

    output:
    path("output.gtf") into mergedAssembly_ch1, mergedAssembly_ch2
    path("output.gtf")

    script:
    """
    stringtie --merge \
    -o output.gtf \
    $gff
    """
}

process filter_transcript {
    publishDir "$params.outdir", mode: "copy"

    input:
    path(assembly_gtf) from mergedAssembly_ch1
    path annot from params.annot

    output:
    path("*_filtered.gtf") into assembly_filter_ch

    script:
    """
    gffcompare -r $annot $assembly_gtf 
    awk '\$3=="u" || \$3=="x" || \$3=="i" {print \$5}' gffcmp.${assembly_gtf}.tmap  > hits.txt
    filter_gff_by_transcriptID.py -i $assembly_gtf -f hits.txt -o merged_filtered.gtf
    """
}

process convert_to_fasta {
    publishDir "$params.outdir", mode: "copy"

    input:
    path genome from params.genome
    path(filtered_gtf) from assembly_filter_ch

    output:
    path("*.fasta") into filtered_fasta_ch1, filtered_fasta_ch2

    script:
    """
    gffread \
    -w transcripts.fasta \
    -g $genome $filtered_gtf
    """
}


// train CPAT in two steps
process cpat_training{

    input:
    path cod from params.mRNA
    path noncod from filtered_fasta_ch1
    val weight from params.weight

    output:
    stdout cutoff into cutoff_ch
    tuple path("final_hexamer.tsv"), path("final.logit.RData") into trainCPAT_ch

    script:
    """
    cpc_cpat_trainingset.py -c $cod -n $noncod -s 80 -o tt_split

    \$CPC2_HOME/bin/CPC2.py -i tt_split_training_noncod.fasta -o tt_split_non_cpc2
    \$CPC2_HOME/bin/CPC2.py -i tt_split_training_cod_cpc.fasta -o tt_split_cod_cpc2

    awk '\$8=="coding" {print \$1}' tt_split_non_cpc2.txt > tt_split_cn_ids.txt
    awk '\$8=="noncoding" {print \$1}' tt_split_non_cpc2.txt > tt_split_nn_ids.txt
    awk '\$8=="coding" {print \$1}' tt_split_cod_cpc2.txt > tt_split_cc_ids.txt
    awk '\$8=="noncoding" {print \$1}' tt_split_cod_cpc2.txt > tt_split_nc_ids.txt

    cpc_cpat_tests.py \
    -c tt_split_training_cod.fasta \
    -n tt_split_training_noncod.fasta \
    -cpc tt_split_training_cod_cpc.fasta \
    -ct tt_split_test_cod.fasta \
    -nt tt_split_test_noncod.fasta \
    -cc tt_split_cc_ids.txt \
    -cn tt_split_cn_ids.txt \
    -nc tt_split_nc_ids.txt \
    -nn tt_split_nn_ids.txt \
    -o final \
    -w $weight

    awk '\$1=="mean" {print \$2}' final_cutoff_data.tsv
    """
}

process cpat_prediction {
    publishDir "$params.outdir", mode: "copy"

    input:
    path(filtered_fasta) from filtered_fasta_ch2
    tuple path(hexamer), path(model) from trainCPAT_ch
    val(cutoff) from cutoff_ch.strip()

    output:
    path("*_ncRNA.fasta") into ncRNA_ch
    path("hits.txt") into hits_ch

    script:
    """
    cpat.py -x $hexamer -d $model -g $filtered_fasta -o cpat_pred
    awk '\$11 < $cutoff {print \$1}' cpat_pred.ORF_prob.best.tsv > hits.txt
    filter_fasta_by_name.py -i $filtered_fasta -f hits.txt -o predicted_ncRNA.fasta
    """
}

process feature_counting {
    tag "$sample_id"
    publishDir "$params.outdir", mode: "copy"

    input:
    tuple val(sample_id), path(bam) from bam_ch
    path(annot) from mergedAssembly_ch2

    output:
    path("*_counts.tsv") into counts_ch

    script:
    """
    htseq-count \
    --stranded=no \
    -n ${task.cpus} \
    -r pos \
    -i transcript_id \
    $bam $annot \
    > ${sample_id}_counts.tsv
    """
}


process diff_analysis {
    publishDir "$params.outdir", mode: "copy"

    input:
    path(counts) from counts_ch.collect()
    path(design) from design_ch
    path(hits) from hits_ch
    // csv with sample name and group in each row

    output:
    path("count_combined.tsv")
    path("*.csv")

    // merge count files from different samples and sort them lexicographically, remove last 5 lines from file
    script:
    """
    merge_counts.py $counts
    # head -n -5 count_combined.tsv > count_combined.tsv
    Rscript $projectDir/DE_analysis.R
    """
}
